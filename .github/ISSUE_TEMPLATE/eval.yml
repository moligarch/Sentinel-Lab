name: Evaluation Task
description: Add or run evaluations (Ragas/LangSmith, perf, data quality).
title: "[Eval] <suite or metric>: <target>"
labels: ["type:eval"]
body:
  - type: dropdown
    id: area
    attributes:
      label: Area
      options: ["RAG/LLM","Perf","Data Quality","SLO"]
  - type: textarea
    id: metrics
    attributes:
      label: Metrics & targets
      placeholder: "faithfulness >= 0.7, p99 <= 200ms, GX suite: all green..."
  - type: textarea
    id: plan
    attributes:
      label: Plan
      description: "Dataset, steps, expected outputs, dashboards to update"
  - type: textarea
    id: dod
    attributes:
      label: Definition of Done
      description: "Adjust the checklist for this specific evaluation run."
      value: |
        - [ ] Results stored under /eval-harness/results/
        - [ ] Pipeline in CI (nightly or on-change)
        - [ ] Report linked in this issue
